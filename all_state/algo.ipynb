{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Roman/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, CountVectorizer\n",
    "from sklearn import manifold, decomposition, linear_model, ensemble, neighbors, cross_validation\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "import re\n",
    "import scipy\n",
    "import hyperopt\n",
    "\n",
    "\n",
    "from heamy.dataset import Dataset\n",
    "from heamy.estimator import Regressor, Classifier\n",
    "from heamy.pipeline import ModelsPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_extra.csv\")\n",
    "test_df = pd.read_csv(\"test_extra.csv\")\n",
    "\n",
    "y = train_df.loss\n",
    "train_df.drop('loss', axis=1, inplace=True)\n",
    "\n",
    "train_df.drop('id', axis=1, inplace=True)\n",
    "test_df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data, y_train, y_test = cross_validation.train_test_split(train_df, y, test_size = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shift = np.log(y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgboost.DMatrix(train_data.values, np.log(y_train) - np.log(y_train).mean())\n",
    "dtest = xgboost.DMatrix(test_data.values, label=np.log(y_test) - np.log(y_train).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    print \"Training with params : \"\n",
    "    print params\n",
    "    num_round = int(params['n_estimators'])\n",
    "    del params['n_estimators']\n",
    "\n",
    "    # watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "    model = xgboost.train(params, dtrain, num_round)\n",
    "    predictions = model.predict(dtest)\n",
    "    score = sklearn.metrics.mean_absolute_error(y_test, np.exp(predictions+shift))\n",
    "    print \"\\tScore: \", score, \"\\n\\n\"\n",
    "    return {'loss': score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimize(trials):\n",
    "    space = {\n",
    "             'n_estimators' : hp.quniform('n_estimators', 100, 1000, 1),\n",
    "             'eta' : hp.quniform('eta', 0.005, 0.5, 0.005),\n",
    "             'max_depth' : hp.quniform('max_depth', 3, 12, 1),\n",
    "             'subsample' : hp.quniform('subsample', 0.3, 1, 0.1),\n",
    "             'gamma' : hp.quniform('gamma', 0.3, 1, 0.1),\n",
    "             'eval_metric': 'rmse',\n",
    "             'nthread' : -1,\n",
    "             'silent' : 1\n",
    "             }\n",
    "\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=250)\n",
    "\n",
    "    print best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params : \n",
      "{'silent': 1, 'eval_metric': 'rmse', 'nthread': -1, 'n_estimators': 280.0, 'subsample': 0.8, 'eta': 0.39, 'max_depth': 9.0, 'gamma': 0.9}\n",
      "\tScore:  1263.7173908 \n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'silent': 1, 'eval_metric': 'rmse', 'nthread': -1, 'n_estimators': 280.0, 'subsample': 0.7000000000000001, 'eta': 0.48, 'max_depth': 10.0, 'gamma': 0.9}\n",
      "\tScore:  1364.47129642 \n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'silent': 1, 'eval_metric': 'rmse', 'nthread': -1, 'n_estimators': 589.0, 'subsample': 0.7000000000000001, 'eta': 0.3, 'max_depth': 10.0, 'gamma': 0.30000000000000004}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "optimize(trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
